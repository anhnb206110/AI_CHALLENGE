{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets transformers sentencepiece datasets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import data_table; data_table.enable_dataframe_formatter()\n",
    "import numpy as np; np.random.seed(123)\n",
    "from accelerate import Accelerator\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import json\n",
    "import gc\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoTokenizer\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "\n",
    "get_ipython().events.register('pre_run_cell', set_css)\n",
    "\n",
    "def clear_cache():\n",
    "  if torch.cuda.is_available():\n",
    "    model = None\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/data/train_data_with_correct_answer.json\", \"r\") as json_file:\n",
    "    dataset = json.load(json_file)\n",
    "dataset = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data: pd.DataFrame):\n",
    "    d=[]\n",
    "    for i in range(len(data)):\n",
    "        if data['options'] != \"\":\n",
    "            d.append(\n",
    "                    {\n",
    "                        \"math\": {\n",
    "                            \"problem\": data['Problem'][i] + \"\\n\" + data['options'],\n",
    "                            \"answer\": data['correct'][i]\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "    print(f'total size of data is {len(d)}')\n",
    "    tdata = pd.DataFrame(d)\n",
    "    tdata = tdata.reset_index()\n",
    "    tdata = tdata.rename(columns={'index': 'id'})\n",
    "    dataset = datasets.Dataset.from_pandas(tdata)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=\"google/flan-t5-base\"\n",
    "# checkpoint=\"NghiemAbe/flan-t5-base-mathqa_v1\"\n",
    "# checkpoint=\"NghiemAbe/flan-t5-base-mathqa_v2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    max_input_length = 512\n",
    "    max_target_length = 512\n",
    "    source = \"problem\"\n",
    "    target = \"answer\"\n",
    "\n",
    "    inputs = [ex[source] for ex in examples[\"math\"]]\n",
    "    targets = [ex[target] for ex in examples[\"math\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "    labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = train_data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE:*\n",
    "\n",
    "Các thông số TrainingArguments cho mỗi lần Finetune xem ở link:\n",
    "- https://huggingface.co/NghiemAbe/flan-t5-base-mathqa_v1\n",
    "- https://huggingface.co/NghiemAbe/flan-t5-base-mathqa_v2\n",
    "- https://huggingface.co/NghiemAbe/flan-t5-base-mathqa_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Seq2SeqTrainingArguments(output_dir=\"/content/drive/MyDrive/flan-t5-base-mathqa_v1/\",\n",
    "                        do_train=True,\n",
    "                        warmup_steps=100,\n",
    "                        optim=\"adamw_torch\",\n",
    "                        per_device_train_batch_size=8,\n",
    "                        gradient_accumulation_steps=1,\n",
    "                        learning_rate=5e-5,\n",
    "                        num_train_epochs=3,\n",
    "                        predict_with_generate=True,\n",
    "                        logging_steps=100,\n",
    "                        save_steps=2000,\n",
    "                        )\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(model=model,\n",
    "                args=args,\n",
    "                data_collator=data_collator,\n",
    "                train_dataset=tokenized_datasets,\n",
    "                tokenizer=tokenizer,\n",
    "                )\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "tokenized_datasets, trainer = accelerator.prepare(\n",
    "     tokenized_datasets, trainer\n",
    "      )\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
