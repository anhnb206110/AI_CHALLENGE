{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jdIEvUjOJAwg"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qgRZFTu9FEq5"
      },
      "outputs": [],
      "source": [
        "!pip install -U openai==0.28.0 datasets transformers peft fire sentencepiece sacrebleu bitsandbytes --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0aA3q6E6FEq8"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import time\n",
        "import json\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S3YEI0n_FEq9"
      },
      "outputs": [],
      "source": [
        "model_name = \"gpt-3.5-turbo-instruct\"\n",
        "finetuned_model = \"NghiemAbe/flan-t5-base-mathqa_v3\"\n",
        "device = \"cuda\"\n",
        "data_path = \"./data/test/all_test_round1.json\"\n",
        "OPEN_API_KEY = [\n",
        "    'sk-flmnoDOca...NgtMxG4Y5kyxsj',\n",
        "    'sk-tfHXOfLqs...vZPyciJn3OVT0j',\n",
        "    'sk-h1s7Mc2WM...sfkhPnzcXwx2bv',\n",
        "    'sk-3tsK40CBq...faxLf18MXrAD2s',\n",
        "    'sk-Je0HwHPXb...5vDPrDvzYlM1o2',\n",
        "    'sk-JHNYqDSfQ...aN6VwQIUO65fbx',\n",
        "    'sk-NBfYfJsQM...OfqIdHhdpUypqe',\n",
        "    'sk-xEKRqAPtS...t9QcaAUV1OhG0N',\n",
        "    'sk-tiSIsPpdU...ASByPrfRtQasrZ',\n",
        "    'sk-AvS3nk3VE...rKxiZMfQ0zhT7Q',\n",
        "    'sk-jpqVKfQ8i...JCUZvLhT8NRlhR',\n",
        "    # 'sk-',    # As much as possible :)\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPYolhDEFEq-",
        "outputId": "61b3f0ec-5728-4cd7-ff4e-70f0c957ff1a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(finetuned_model)\n",
        "model = T5ForConditionalGeneration.from_pretrained(finetuned_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW4sw1IPFEq_",
        "outputId": "774260e9-fecd-4a49-b9c0-09d2346354a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "K76BmaPFFErA"
      },
      "outputs": [],
      "source": [
        "def read_jsonl(path: str):\n",
        "    with open(path) as f:\n",
        "        data = json.load(f)\n",
        "        return data\n",
        "\n",
        "\n",
        "def get_data(path):\n",
        "    '''\n",
        "        If there are many json files to load:\n",
        "        path_item = os.path.join(\"data/\", f\"{path}.jsonl\")\n",
        "        data_item = read_jsonl(path_item)\n",
        "    '''\n",
        "    data = read_jsonl(path)\n",
        "    print(f\"Loaded {len(data)} examples\")\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_aIXDxNDFErA"
      },
      "outputs": [],
      "source": [
        "def get_response(user_request, max_len, temp):\n",
        "    \"\"\"\n",
        "        Get a response from the OpenAI API based on the given arguments.\n",
        "\n",
        "        Args:\n",
        "            args (object): The arguments object containing the model name, user request, maximum length, and temperature.\n",
        "            user_request (str): The user's request to be used as the prompt for generating a response.\n",
        "            max_len (int): The maximum number of tokens in the generated response.\n",
        "            temp (float): The temperature parameter for controlling the randomness of the generated response.\n",
        "\n",
        "        Returns:\n",
        "            object: The response generated by the OpenAI API.\n",
        "    \"\"\"\n",
        "    responese = openai.Completion.create(\n",
        "        engine = model_name,\n",
        "        prompt = user_request,\n",
        "        max_tokens = max_len,\n",
        "        n = 1,\n",
        "        temperature = temp\n",
        "    )\n",
        "\n",
        "    return responese\n",
        "\n",
        "def get_multiple_choice_answer(prompt):\n",
        "    tokens = tokenizer([prompt], padding=False, return_tensors=\"pt\").to(device)\n",
        "    out = model.generate(\n",
        "        **tokens, max_length=10, pad_token_id=model.config.eos_token_id\n",
        "    )\n",
        "    result = tokenizer.batch_decode(out, skip_special_tokens=True)[0]\n",
        "    return result\n",
        "\n",
        "def convert_to_submit_file(api_result: list = []):\n",
        "    if api_result[0].isalpha():\n",
        "        return api_result[0].lower()\n",
        "    else:\n",
        "        if 'frac' in api_result or 'pi' in api_result:\n",
        "            api_result = api_result.split()[0].replace('$','')\n",
        "        else:\n",
        "            api_result = ''.join(re.findall(r'[0-9\\.\\-]+', api_result))\n",
        "        if len(api_result) and api_result[-1] == '.':\n",
        "            api_result = api_result[:-1]\n",
        "        answer = api_result\n",
        "        return answer.lower()\n",
        "    return 'Nan'\n",
        "\n",
        "def run():\n",
        "    api_keys = OPEN_API_KEY\n",
        "    key_index = 0\n",
        "    test_examples = get_data(data_path)\n",
        "    results = []\n",
        "    with open('./results/result.txt', 'r') as read:\n",
        "        results = read.readlines()\n",
        "    curr_indx = 1\n",
        "    last_indx = len(results)\n",
        "    print(\"Last request: \", last_indx)\n",
        "    max_len = 10\n",
        "    temp = 0.05\n",
        "    prompt = \"Please give me a number that is the answer to this question, no explanation, no units, just a single number:\"\n",
        "\n",
        "    with open('./results/result.txt', 'a+') as f:\n",
        "        for problem in test_examples:\n",
        "            ques = problem[\"Problem\"]\n",
        "            options = problem[\"options\"]\n",
        "            responese = {}\n",
        "            if curr_indx > last_indx:\n",
        "                if options != '':\n",
        "                    start = time.time()\n",
        "                    result = get_multiple_choice_answer(\"Give me the answer of this question:\" + ques + '\\n'+ options)\n",
        "                    finish = time.time()\n",
        "                    time_request = finish - start\n",
        "                    print(f\"Time generate for {problem['id']}: {time_request}, answer: {result}\")\n",
        "                else:\n",
        "                    while 'id' not in responese:\n",
        "                        try:\n",
        "                            openai.api_key = api_keys[key_index]\n",
        "                            print(\"API KEY: \", openai.api_key[:10] + \"...\" + openai.api_key[-10:])\n",
        "                            start = time.time()\n",
        "                            user_request = prompt + ques\n",
        "                            responese = get_response(user_request, max_len, temp)\n",
        "                            finish = time.time()\n",
        "                            time_request = finish - start\n",
        "                            result = responese.choices[0].text.strip()\n",
        "                        except openai.error.RateLimitError:\n",
        "                            if key_index == 0:\n",
        "                                print(\"Waiting...\")\n",
        "                                time.sleep(5)\n",
        "                            continue\n",
        "                        finally:\n",
        "                            key_index = (key_index + 1) % len(api_keys)\n",
        "                    print(f\"Time request for {problem['id']}: {time_request}, answer: {result}\")\n",
        "                choose = convert_to_submit_file(result)\n",
        "                f.write(choose + '\\t' + str(time_request) + '\\n')\n",
        "            curr_indx += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "js4nQIESFErC"
      },
      "outputs": [],
      "source": [
        "run()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
